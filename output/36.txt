<html>
<head>
<title>Модель пАрной линейной регрессии и не только. Индекс корреляции и индекс детерминации. Средняя ошибка аппроксимации</title>

<meta http-equiv="content-type" content="text/html; charset=windows-1251">
<meta name="author" content="Александр Емелин">
<meta name="Keywords" content="однофакторная регрессия, парная регрессия, линейная регрессия, нелинейная регрессии, модель регрессии, примеры решений, общая дисперсия, факторная дисперсия, остаточная дисперсия, индекс детерминации, индекс корреляции, что такое, как найти, качество модели, средняя ошибка аппроксимации">
<meta name="Description" content="Корреляционно-регрессионный анализ для «чайников». Примеры, решения, медведи и цыгане с балалайками">

<link href="style.css" rel="stylesheet" type="text/css">

<link rel="icon" href="/favicon.ico" type="image/x-icon">
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
<!-- Yandex.RTB -->
<script>window.yaContextCb=window.yaContextCb||[]</script>
<script src="https://yandex.ru/ads/system/context.js" async></script></head>

<body  >


<table width="980"  border="1" cellpadding="0" cellspacing="0" align="center">


<tr>
<td colspan="2" width="980" height="220" align="center" > 

<img src="images/head.jpg" border="0" alt="Математика для заочников и не только">
  <p class=classh align="center"><img align="absmiddle" border="0" src="images/kljuchik.jpg" border="0"> Высшая математика – просто и доступно!</p>  
<p align="center"> <img align="absmiddle" src="images/mark.jpg" border="0"> Если сайт упал, используйте ЗЕРКАЛО: <a href="https://mathprofi.net"> mathprofi.net</a></p>
<p align="center"> <img align="absmiddle" src="images/mark.jpg" border="0"> Наш форум, библиотека и блог <a href="https://mathprofi.com">mathprofi<img align="absmiddle" src="images/dotcom.gif" border="0"></a>>>></p>
</td></tr>

<tr>

<td width="27%" valign="top" > 

<br>
<p class=classbar>Высшая математика:</p>

<p class=classb>

<a href="index.html">Математика для заочников</a>
        </p><p class=classb>
<a href="matematicheskie_formuly.html">Математические формулы,<br>таблицы и другие материалы</a>
        </p><p class=classb>
<a href="https://mathprofi.com/blog/dostupnye_knigi_po_vysshey_matematike.html" target="_blank">Книги по математике</a>
        </p><p class=classb>
<a href="saity_po_matematike.html">Математические сайты </a></p>

<p class=classb><a href="files/kalkulyator.matprofi.ru.zip">+-*/^ Удобный калькулятор</a></p>
<p><a href="files/drobovik.xls">+ «Дробовик»</a>&nbsp;&nbsp;&nbsp;<img align="absmiddle" src="images/new.png" border="0"></p>


<p class=classbar>Учимся решать:</p>
<p> <img src="images/pervyi_kurs.png" border="0" alt="Лекции-уроки по высшей математике для первого курса"></p>

<div id="bar1">

<p class=classs>

<a class=classbar href="matematika_dlya_chainikov.html">Высшая математика для чайников, или с чего начать?</a><br>
<a class=classbar href="https://mathter.pro/pesochnica/index.html" target="_blank"><img align="absmiddle" src="images/pesochnica3.png" border="0"> Повторяем школьный курс</a></p>

<p class=classtopic>
Аналитическая геометрия:
</p>
<p class=classs>

<a class=classbar href="vektory_dlya_chainikov.html">Векторы для чайников</a>
<br>
<a class=classbar href="skaljarnoe_proizvedenie_vektorov.html">Скалярное произведение <br>векторов</a>
<br>
<a class=classbar href="linejnaja_nezavisimost_vektorov_bazis_vektorov.html">Линейная (не) зависимость<br>векторов. Базис векторов</a>
<br>
<a class=classbar href="perehod_k_novomu_bazisu.html">Переход к новому базису</a>
<br>
<a class=classbar href="vektornoe_proizvedenie_vektorov_smeshannoe_proizvedenie.html">Векторное и смешанное<br>произведение векторов</a>
<br>
<a class=classbar href="delenie_otrezka_v_dannom_otnoshenii.html">Формулы деления отрезка<br>в данном отношении</a>
<br>
<a class=classbar href="uravnenie_pryamoi_na_ploskosti.html">Прямая на плоскости</a>
<br>
<a class=classbar href="zadachi_s_pryamoi_na_ploskosti.html">Простейшие задачи<br>с прямой на плоскости</a>
<br>
<a class=classbar href="lineinye_neravenstva.html">Линейные неравенства</a>
<br>
<a class=classbar href="kak_nauchitsa_reshat_zadachi_po_geometrii.html">Как научиться решать задачи<br>по аналитической геометрии?</a>
<br>
<a class=classbar href="linii_vtorogo_poryadka_ellips_i_okruzhnost.html">Линии второго порядка. Эллипс</a>
<br>
<a class=classbar href="giperbola_i_parabola.html">Гипербола и парабола</a>
<br>
<a class=classbar href="zadachi_s_liniyami_2_poryadka.html">Задачи с линиями 2-го порядка</a>
<br>
<a class=classbar href="kak_privesti_uravnenie_linii_2_poryadka_k_kanonicheskomu_vidu.html">Как привести уравнение л. 2 п.<br>к каноническому виду?</a>
<br>
<a class=classbar href="poljarnye_koordinaty.html">Полярные координаты</a>
<br>
<a class=classbar href="kak_postroit_liniju_v_poljarnoi_sisteme_koordinat.html">Как построить линию<br>в полярной системе координат?</a>
<br>
<a class=classbar href="uravnenie_ploskosti.html">Уравнение плоскости</a>
<br>
<a class=classbar href="uravnenija_pryamoi_v_prostranstve.html">Прямая в пространстве</a>
<br>
<a class=classbar href="zadachi_s_pryamoi_v_prostranstve.html">Задачи с прямой в пространстве</a>
<br>
<a class=classbar href="zadachi_s_pryamoi_i_ploskostju.html">Основные задачи<br>на прямую и плоскость</a>
<br>
<a class=classbar href="treugolnaya_piramida.html">Треугольная пирамида</a>
</p>



<p class=classtopic>
Элементы высшей алгебры:
</p>

<p class=classs>

<a class=classbar href="mnozhestva.html">Множества и действия над ними</a>
<br>
<a class=classbar href="osnovy_matematicheskoj_logiki.html">Основы математической логики</a>
<br>
<a class=classbar href="formuly_i_zakony_logiki.html">Формулы и законы логики</a>
<br>
<a class=classbar href="uravnenija_v_vysshei_matematike.html">Уравнения высшей математики</a>
<br>
<a class=classbar href="racionalnye_korni_mnogochlena_shema_gornera.html">Как найти рациональные корни<br>многочлена? Схема Горнера</a>
<br>
<a class=classbar href="kompleksnye_chisla_dlya_chainikov.html">Комплексные числа</a>
<br>
<a class=classbar href="vyrazhenija_uravnenija_i_sistemy_s_ kompleksnymi_chislami.html">Выражения, уравнения и с-мы<br>с комплексными числами</a>
<br>
<a class=classbar href="deistviya_s_matricami.html">Действия с матрицами</a>
<br>
<a class=classbar href="kak_vychislit_opredelitel.html">Как вычислить определитель?</a>
<br>
<a class=classbar href="svoistva_opredelitelya_ponizhenie_poryadka_opredelitelya.html">Свойства определителя<br>и понижение его порядка</a>
<br>
<a class=classbar href="kak_naiti_obratnuyu_matricu.html">Как найти обратную матрицу?</a>
<br>
<a class=classbar href="svoistva_operacij_nad_matricami_matrichnye_vyrazheniya.html">Свойства матричных операций.<br>Матричные выражения</a>
<br>
<a class=classbar href="matrichnye_uravneniya_primery_reshenij.html">Матричные уравнения</a>
<br>
<a class=classbar href="kak_reshit_sistemu_uravnenii.html">Как решить систему линейных уравнений?</a>
<br>
<a class=classbar href="pravilo_kramera_matrichnyi_metod.html">Правило Крамера. Матричный метод решения системы</a>
<br>
<a class=classbar href="metod_gaussa_dlya_chainikov.html">Метод Гаусса для чайников</a>
<br>
<a class=classbar href="slu_nesovmestnye_sistemy_i_sistemy_s_obshim_resheniem.html">Несовместные системы<br>и системы с общим решением</a>
<br>
<a class=classbar href="rang_matricy.html">Как найти ранг матрицы?</a>
<br>
<a class=classbar href="odnorodnye_sistemy_lineinyh_uravnenij.html">Однородные системы<br>линейных уравнений</a>
<br>
<a class=classbar href="metod_zhordano_gaussa_nahozhdenie_obratnoi_matricy.html">Метод Гаусса-Жордана</a>
<br>
<a class=classbar href="reshenie_systemy_pri_razlichnyh_sposobah_vybora_bazisa.html">Решение системы уравнений<br>в различных базисах</a>
<br>
<a class=classbar href="linejnye_preobrazovanija.html">Линейные преобразования</a>
<br>
<a class=classbar href="sobstvennye_znachenija_i_sobstvennye_vektory.html">Собственные значения<br>и собственные векторы</a>
<br>
<a class=classbar href="kvadratichnye_formy.html">Квадратичные формы</a>
<br>
<a class=classbar href="kak_privesti_kf_k_kanonicheskomu_vidu.html">Как привести квадратичную<br>форму к каноническому виду?</a>
<br>
<a class=classbar href="metod_ortogonalnogo_preobrazovaniya_kf.html">Ортогональное преобразование<br>квадратичной формы</a>

</p>

<p class=classtopic>
Пределы:
</p>
<p class=classs>

<a class=classbar href="predely_primery_reshenii.html">Пределы. Примеры решений</a>
<br>
<a class=classbar href="zamechatelnye_predely.html">Замечательные пределы</a>
<br>
<a class=classbar href="metody_resheniya_predelov_neopredelennosti.html">Методы решения пределов</a>
<br>
<a class=classbar href="beskonechno_malye_funkcii_zamechatelnye_ekvivalentnosti.html">Бесконечно малые функции.<br>Эквивалентности</a>
<br>
<a class=classbar href="pravila_lopitalya.html">Правила Лопиталя</a>
<br>
<a class=classbar href="slozhnye_predely.html">Сложные пределы</a>
<br>
<a class=classbar href="predel_posledovatelnosti.html">Пределы последовательностей</a>
<br>
<a class=classbar href="predely_po_koshi.html">Пределы по Коши. Теория</a>
</p>

<p class=classtopic>
Производные функций:
</p>
<p class=classs>


<a class=classbar href="kak_naiti_proizvodnuju.html">Как найти производную?</a>
<br>
<a class=classbar href="proizvodnaya_slozhnoi_funkcii.html">Производная сложной функции. Примеры решений</a>
<br>
<a class=classbar href="slozhnye_proizvodnye_logarifmicheskaja_proizvodnaja.html">Логарифмическая производная</a>
<br>
<a class=classbar href="proizvodnye_neyavnoi_parametricheskoi_funkcii.html">Производные неявной, параметрической функций</a>
<br>
<a class=classbar href="tipovye_zadachi_s_proizvodnoi.html">Простейшие задачи<br> с производной</a>
<br>
<a class=classbar href="proizvodnye_vysshih_porjadkov.html">Производные высших порядков</a>
<br>
<a class=classbar href="opredelenie_proizvodnoi_smysl_proizvodnoi.html">Что такое производная?</a>
<br>
<a class=classbar href="proizvodnaya_po_opredeleniju_primery_reshenii.html">Производная по определению</a>
<br>
<a class=classbar href="kak_naiti_uravnenie_normali.html">Как найти уравнение нормали?</a>
<br>
<a class=classbar href="priblizhennye_vychislenija_s_pomoshju_differenciala.html">Приближенные вычисления<br>с помощью дифференциала</a>
<br>
<a class=classbar href="metod_kasatelnyh.html">Метод касательных</a>
</p>

<p class=classtopic>
Функции и графики:
</p>
<p class=classs>

<a class=classbar href="grafiki_i_svoistva_funkcij.html">Графики и свойства<br>элементарных функций</a>
<br>
<a class=classbar href="kak_postroit_grafik_funkcii_s_pomoshyu_preobrazovanii.html">Как построить график функции<br>с помощью преобразований?</a>
<br>
<a class=classbar href="nepreryvnost_funkcii_i_tochki_razryva.html">Непрерывность, точки разрыва</a>
<br>
<a class=classbar href="oblast_opredeleniya.html">Область определения функции</a>
<br>
<a class=classbar href="asimptoty_grafika_funkcii.html">Асимптоты графика функции</a>
<br>
<a class=classbar href="nuli_funkcii_intervaly_znakopostoyanstva_metod_intervalov.html">Интервалы знакопостоянства</a>
<br>
<a class=classbar href="vozrastanie_ubyvanie_ekstremumy_funkcii.html">Возрастание, убывание<br>и экстремумы функции</a>
<br>
<a class=classbar href="vypuklost_vognutost_tochki_peregiba_grafika.html">Выпуклость, вогнутость<br>и точки перегиба графика</a>
<br>
<a class=classbar href="polnoe_issledovanie_funkcii_i_postroenie_grafika.html">Полное исследование функции<br>и построение графика</a>
<br>
<a class=classbar href="naibolshee_i_naimenshee_znacheniya_funkcii_na_otrezke.html">Наибольшее и наименьшее<br>значения функции на отрезке</a>
<br>
<a class=classbar href="zadachi_na_minimumy_i_maksimumy.html">Экстремальные задачи</a>
</p>


<p class=classtopic>
ФНП:
</p>
<p class=classs>
<a class=classbar href="funkcija_dvuh_peremennyh_oblast_opredelenija_linii_urovnja.html">Область определения функции<br>двух переменных. Линии уровня</a>
<br>
<a class=classbar href="poverhnosti.html">Основные поверхности</a>
<br>
<a class=classbar href="predel_funkcii_dvuh_peremennyh.html">Предел функции 2 переменных</a>
<br>
<a class=classbar href="povtornye_predely.html">Повторные пределы</a>
<br>
<a class=classbar href="nepreryvnost_funkcii_dvuh_peremennyh.html">Непрерывность функции 2п</a>
<br>
<a class=classbar href="chastnye_proizvodnye_primery.html">Частные производные</a>
<br>
<a class=classbar href="chastnye_proizvodnye_funkcii_treh_peremennyh.html">Частные производные<br>функции трёх переменных</a>
<br>
<a class=classbar href="proizvodnye_slozhnyh_funkcij_neskolkih_peremennyh.html">Производные сложных функций<br>нескольких переменных</a>
<br>
<a class=classbar href="kak_proverit_udovletvorjaet_li_funkcija_uravneniju.html">Как проверить, удовлетворяет<br>ли функция уравнению?</a>
<br>
<a class=classbar href="chastnye_proizvodnye_nejavno_zadannoj_funkcii.html">Частные производные<br>неявно заданной функции</a>
<br>
<a class=classbar href="proizvodnaja_po_napravleniju_i_gradient.html">Производная по направлению<br>и градиент функции</a>
<br>
<a class=classbar href="kasatelnaja_ploskost_i_normal_k_poverhnosti_v_tochke.html">Касательная плоскость и<br>нормаль к поверхности в точке</a>
<br>
<a class=classbar href="extremumy_funkcij_dvuh_i_treh_peremennyh.html">Экстремумы функций<br>двух и трёх переменных</a>
<br>
<a class=classbar href="uslovnye_extremumy.html">Условные экстремумы</a>
<br>
<a class=classbar href="naibolshee_i_naimenshee_znachenija_funkcii_v_oblasti.html">Наибольшее и наименьшее<br>значения функции в области</a>
<br>
<a class=classbar href="metod_naimenshih_kvadratov.html">Метод наименьших квадратов</a>
</p>


<p class=classtopic>
Интегралы:
</p>
<p class=classs>

<a class=classbar href="integraly_primery_reshenij.html">Неопределенный интеграл.<br>Примеры решений</a>
<br>
<a class=classbar href="metod_zameny_peremennoi.html">Метод замены переменной<br> в неопределенном интеграле</a>
<br>
<a class=classbar href="integrirovanie_po_chastyam.html">Интегрирование по частям</a>
<br>
<a class=classbar href="integraly_ot_trigonometricheskih_funkcij.html">Интегралы от тригонометрических функций</a>
<br>
<a class=classbar href="integrirovanie_drobei.html">Интегрирование дробей</a>
<br>
<a class=classbar href="integraly_ot_drobno_racionalnoj_funkcii.html">Интегралы от дробно-рациональных функций</a>
<br>
<a class=classbar href="integrirovanie_kornei.html">Интегрирование иррациональных функций</a>
<br>
<a class=classbar href="slozhnye_integraly.html">Сложные интегралы</a>
<br>
<a class=classbar href="opredelennye_integraly_primery_reshenij.html">Определенный интеграл</a>
<br>
<a class=classbar href="vychislenie_ploshadi_c_pomoshju_opredelennogo_integrala.html">Как вычислить площадь<br>с помощью определенного интеграла?</a>
<br>
<a class=classbar href="chto_takoe_integral_teorija_dlja_chainikov.html">Что такое интеграл?<br>Теория для чайников</a>
<br>
<a class=classbar href="obyem_tela_vrashenija.html">Объем тела вращения</a>
<br>
<a class=classbar href="nesobstvennye_integraly.html">Несобственные интегралы</a>
<br>
<a class=classbar href="metody_reshenija_opredelennyh_i_nesobstvennyh_integralov.html">Эффективные методы решения<br>определенных и несобственных<br>интегралов</a>
<br>
<a class=classbar href="kak_issledovat_shodimost_nesobstvennogo_integrala.html">Как исследовать несобственный<br>интеграл на сходимость?</a>
<br>
<a class=classbar href="priznaki_shodimosti_nesobstvennyh_integralov_vtorogo_roda.html">Признаки сходимости несобств.<br>интегралов второго рода</a>
<br>
<a class=classbar href="absolyutnaya_i_uslovnaya_shodimost_nesobstvennogo_integrala.html">Абсолютная и условная<br>сходимость несобств. интеграла</a>
<br>
<a class=classbar href="ploshad_v_poljarnyh_koordinatah.html">S в полярных координатах</a>
<br>
<a class=classbar href="ploshad_i_obyem_esli_linija_zadana_parametricheski.html">S и V, если линия задана<br>в параметрическом виде</a>
<br>
<a class=classbar href="dlina_dugi_krivoi.html">Длина дуги кривой</a>
<br>
<a class=classbar href="ploshad_poverhnosti_vrashenija.html">S поверхности вращения</a>
<br>
<a class=classbar href="formula_simpsona_metod_trapecij.html">Приближенные вычисления<br>определенных интегралов</a>
<br>
<img align="absmiddle" src="images/plus.png" border="0">
<br>
<a class=classbar href="metod_prjamougolnikov.html">Метод прямоугольников</a>

</p>
</div>


<noindex>
<p>
<div class="adv">

<!-- Yandex.RTB R-A-1373053-9 -->
<div id="yandex_rtb_R-A-1373053-9"></div>
<script>window.yaContextCb.push(()=>{
  Ya.Context.AdvManager.render({
    renderTo: 'yandex_rtb_R-A-1373053-9',
    blockId: 'R-A-1373053-9'
  })
})</script>

</div>
</p>
</noindex>


<p><a href="lekcii_po_vysshei_matematike.html"><img align="absmiddle" src="images/sun3.png" border="0">&nbsp;&nbsp;Карта сайта</a></p>

<p> <img src="images/vtoroi_kurs.png" border="0" alt="Лекции-уроки по высшей математике для второго курса"></p>

<div id="bar1">

<p class=classtopic>
Дифференциальные уравнения:
</p>
<p class=classs>

<a class=classbar href="differencialnye_uravnenija_primery_reshenii.html">Дифференциальные уравнения первого порядка</a>
<br>
<a class=classbar href="odnorodnye_diffury_pervogo_poryadka.html">Однородные ДУ 1-го порядка</a>
<br>
<a class=classbar href="du_svodjashiesja_k_odnorodnym.html">ДУ, сводящиеся к однородным</a>
<br>
<a class=classbar href="lineinye_differencialnye_uravnenija.html">Линейные неоднородные дифференциальные уравнения первого порядка</a>
<br>
<a class=classbar href="differencialnye_uravnenija_v_polnyh_differencialah.html">Дифференциальные уравнения в полных дифференциалах</a>
<br>
<a class=classbar href="differencialnoe_uravnenie_bernulli.html">Уравнение Бернулли</a>
<br>
<a class=classbar href="differencialnye_uravnenija_dopuskajushie_ponizhenie_poryadka.html">Дифференциальные уравнения<br>с понижением порядка</a>
<br>
<a class=classbar href="differencialnye_uravnenija_vtorogo_poryadka.html">Однородные ДУ 2-го порядка</a>
<br>
<a class=classbar href="kak_reshit_neodnorodnoe_uravnenie_vtorogo_poryadka.html">Неоднородные ДУ 2-го порядка</a>
<br>
<a class=classbar href="linejnye_diffury_vysshih_porjadkov.html">Линейные дифференциальные<br>уравнения высших порядков</a>
<br>
<a class=classbar href="metod_variacii_proizvolnyh_postoyannyh.html"> Метод вариации <br>произвольных постоянных</a>
<br>
<a class=classbar href="sistemy_differencialnyh_uravnenij.html">Как решить систему<br>дифференциальных уравнений</a>
<br>
<a class=classbar href="zadachi_s_diffurami.html">Задачи с диффурами</a>
<br>
<a class=classbar href="metody_eilera_i_runge_kutty.html">Методы Эйлера и Рунге-Кутты</a>

</p>
<p class=classtopic>
Числовые ряды:
</p>
<p class=classs>

<a class=classbar href="ryady_dlya_chajnikov.html">Ряды для чайников</a>
<br>
<a class=classbar href="kak_naiti_summu_ryada.html">Как найти сумму ряда?</a>
<br>
<a class=classbar href="priznak_dalambera_priznaki_koshi.html">Признак Даламбера. <br>Признаки Коши</a>
<br>
<a class=classbar href="priznak_leibnica_primery_reshenii.html">Знакочередующиеся ряды. Признак Лейбница</a>
<br>
<a class=classbar href="slozhnye_ryady.html">Ряды повышенной сложности</a>

</p>
<p class=classtopic>
Функциональные ряды:
</p>
<p class=classs>

<a class=classbar href="funkcionalnye_i_stepennye_ryady.html">Степенные ряды</a>
<br>
<a class=classbar href="razlozhenie_funkcij_v_stepennye_ryady.html">Разложение функций<br>в степенные ряды</a>
<br>
<a class=classbar href="summa_stepennogo_ryada.html">Сумма степенного ряда</a>
<br>
<a class=classbar href="ravnomernaja_shodimost.html">Равномерная сходимость</a>
<br>
<a class=classbar href="slozhnye_funkcionalnye_ryady.html">Другие функциональные ряды</a>
<br>
<a class=classbar href="priblizhennye_vychislenia_s_pomoshju_ryadov.html">Приближенные вычисления<br>с помощью рядов</a>
<br>
<a class=classbar href="vychislenie_integrala_razlozheniem_v_ryad.html">Вычисление интеграла разложением функции в ряд</a>
<br>
<a class=classbar href="chastnoe_reshenie_du_priblizhenno_s_pomoshju_ryada.html">Как найти частное решение ДУ<br>приближённо с помощью ряда?</a>
<br>
<a class=classbar href="predel_s_pomoshju_riada.html">Вычисление пределов</a>
<br>
<a class=classbar href="ryady_furie_primery_reshenij.html">Ряды Фурье. Примеры решений</a>

</p>
<p class=classtopic>
Кратные интегралы:
</p>
<p class=classs>

<a class=classbar href="dvoinye_integraly_dlya_chainikov.html">Двойные интегралы</a>
<br>
<a class=classbar href="kak_vychislit_dvoinoi_integral.html">Как вычислить двойной<br> интеграл? Примеры решений</a>
<br>
<a class=classbar href="dvoinye_integraly_v_poljarnyh_koordinatah.html">Двойные интегралы<br>в полярных координатах</a>
<br>
<a class=classbar href="centr_tjazhesti_ploskoi_figury.html">Как найти центр тяжести<br>плоской фигуры?</a>
<br>
<a class=classbar href="troinye_integraly.html">Тройные интегралы</a>
<br>
<a class=classbar href="primery_reshenij_proizvolnyh_troinyh_integralov.html">Как вычислить произвольный<br>тройной интеграл?</a>
<br>
<img align="absmiddle" src="images/plus.png" border="0">
<br>
<a class=classbar href="krivolineinye_integraly.html">Криволинейные интегралы</a>
<br>
<a class=classbar href="ki_po_zamknutomu_konturu_formula_grina.html">Интеграл по замкнутому контуру<br>Формула Грина. Работа силы</a>
<br>
<a class=classbar href="poverhnostnye_integraly.html">Поверхностные интегралы</a>
</p>

<p class=classtopic>
Элементы векторного анализа:
</p>
<p class=classs>
<a class=classbar href="teoriya_polya.html">Основы теории поля</a>
<br>
<a class=classbar href="potok_vektornogo_polya.html">Поток векторного поля</a>
<br>
<a class=classbar href="divergenciya_vektornogo_polya.html">Дивергенция векторного поля<br>Формула Гаусса-Остроградского</a>
<br>
<a class=classbar href="cirkulyaciya_vektornogo_polya.html">Циркуляция векторного поля<br>и формула Стокса</a>
</p>

<p class=classtopic>
Комплексный анализ:
</p>
<p class=classs>

<a class=classbar href="funkcii_kompleksnoi_peremennoi.html">Примеры решений типовых<br>задач комплексного анализа</a>
<br>
<a class=classbar href="kak_naiti_kompleksnuju_funkciju.html">Как найти функцию<br>комплексной переменной?</a>
<br>
<a class=classbar href="reshenie_diffurov_metodom_operacionnogo_ischislenija.html">Решение ДУ методом<br>операционного исчисления</a>
<br>
<a class=classbar href="kak_reshit_sistemu_du_operacionnym_metodom.html">Как решить систему ДУ<br>операционным методом?</a>

</p>


<p class=classtopic>
Теория вероятностей:
</p>
<p class=classs>

<a class=classbar href="teorija_verojatnostei.html">Основы теории  вероятностей</a>
<br>
<a class=classbar href="zadachi_po_kombinatorike_primery_reshenij.html">Задачи по комбинаторике</a>
<br>
<a class=classbar href="zadachi_na_klassicheskoe_opredelenie_verojatnosti_primery_reshenij.html">Задачи на классическое<br>определение вероятности</a>
<br>
<a class=classbar href="geometricheskoe_opredelenie_verojatnosti.html">Геометрическая вероятность</a>
<br>
<a class=classbar href="teoremy_slozhenija_i_umnozhenija_verojatnostei.html">Задачи на теоремы сложения<br>и умножения вероятностей</a>
<br>
<a class=classbar href="zavisimye_sobytija.html">Зависимые события</a>
<br>
<a class=classbar href="formula_polnoj_verojatnosti_formuly_bajesa.html">Формула полной вероятности<br>и формулы Байеса</a>
<br>
<a class=classbar href="nezavisimye_ispytanija_i_formula_bernulli.html">Независимые испытания<br>и формула Бернулли</a>
<br>
<a class=classbar href="lokalnaja_i_integralnaja_teoremy_laplasa.html">Локальная и интегральная<br>теоремы Лапласа</a>
<br>
<a class=classbar href="statisticheskoe_opredelenie_verojatnosti.html">Статистическая вероятность</a>
<br>
<a class=classbar href="sluchainaya_velichina.html">Случайные величины.<br>Математическое ожидание</a>
<br>
<a class=classbar href="dispersia_diskretnoi_sluchainoi_velichiny.html">Дисперсия дискретной<br>случайной величины</a>
<br>
<a class=classbar href="funkcia_raspredeleniya_dsv.html">Функция распределения</a>
<br>
<a class=classbar href="geometricheskoe_raspredelenie_veroyatnostei.html">Геометрическое распределение</a>
<br>
<a class=classbar href="binomialnoe_raspredelenie_veroyatnostei.html">Биномиальное распределение</a>
<br>
<a class=classbar href="raspredelenie_i_formula_puassona.html">Распределение Пуассона</a>
<br>
<a class=classbar href="gipergeometricheskoe_raspredelenie_veroyatnostei.html">Гипергеометрическое<br>распределение вероятностей</a>
<br>
<a class=classbar href="nepreryvnaya_sluchaynaya_velichina.html">Непрерывная случайная<br>величина, функции F(x) и f(x)</a>
<br>
<a class=classbar href="matematicheskoe_ozhidanie_i_dispersiya_nsv.html">Как вычислить математическое<br>ожидание и дисперсию НСВ?</a>
<br>
<a class=classbar href="ravnomernoe_raspredelenie_veroyatnostei.html">Равномерное распределение</a>
<br>
<a class=classbar href="pokazatelnoe_raspredelenie_veroyatnostei.html">Показательное распределение</a>
<br>
<a class=classbar href="normalnoe_raspredelenie_veroyatnostei.html">Нормальное распределение</a>
<br>
<a class=classbar href="sistema_sluchainyh_velichin.html">Система случайных величин</a>
<br>
<a class=classbar href="zavisimye_i_nezavisimye_sluchainye_velichiny.html">Зависимые и независимые<br>случайные величины</a>
<br>
<a class=classbar href="dvumernaya_nepreryvnaya_sluchaynaya_velichina.html">Двумерная непрерывная<br>случайная величина</a>
<br>
<a class=classbar href="zavisimost_i_koefficient_kovariacii_nsv.html">Зависимость и коэффициент<br>ковариации непрерывных СВ</a>
</p>


<p class=classtopic>Математическая статистика:</p>

<p class=classs>

<a class=classbar href="matematicheskaya_statistika.html">Математическая статистика</a>
<br>
<a class=classbar href="diskretnyi_variacionnyi_ryad.html">Дискретный вариационный ряд</a>
<br>
<a class=classbar href="intervalnyi_variacionnyi_ryad.html">Интервальный ряд</a>
<br>
<a class=classbar href="moda_mediana_generalnaya_i_vyborochnaya_srednyaya.html">Мода, медиана, средняя</a>
<br>
<a class=classbar href="pokazateli_variacii_generalnaya_i_vyborochnaya_dispersiya.html">Показатели вариации</a>
<br>
<a class=classbar href="formula_dispersii_standartnoe_otklonenie_koefficient_variacii.html">Формула дисперсии, среднее<br>квадратическое отклонение,<br>коэффициент вариации</a>
<br>
<a class=classbar href="asimmetriya_i_excess.html">Асимметрия и эксцесс<br>эмпирического распределения</a>
<br>
<a class=classbar href="statisticheskie_ocenki_parametrov_generalnoy_sovokupnosti.html">Статистические оценки<br>и доверительные интервалы</a>
<br>
<a class=classbar href="ocenka_veroyatnosti_binomialnogo_raspredeleniya.html">Оценка вероятности<br>биномиального распределения</a>
<br>
<a class=classbar href="ocenki_po_povtornoy_i_bespovtornoy_vyborke.html">Оценки по повторной<br>и бесповторной выборке</a>
<br>
<a class=classbar href="statisticheskie_gipotezy.html">Статистические гипотезы</a>
<br>
<a class=classbar href="proverka_statisticheskih_gipotez.html">Проверка гипотез. Примеры</a>
<br>
<a class=classbar href="kriteriy_soglasiya.html">Гипотеза о виде распределения<br>Критерий согласия Пирсона</a>
<br>
<a class=classbar href="gruppirovka_dannyh.html">Группировка данных. Виды группировок. Перегруппировка</a>
<br>
<a class=classbar href="dispersii.html">Общая, внутригрупповая<br>и межгрупповая дисперсия</a>
<br>
<a class=classbar href="analiticheskaya_gruppirovka.html">Аналитическая группировка</a>
<br>
<a class=classbar href="kombinacionnaya_gruppirovka.html">Комбинационная группировка</a>
<br>
<a class=classbar href="empiricheskie_pokazateli.html">Эмпирические показатели</a>
<br>
<a class=classbar href="linejnyj_koefficient_korrelyacii.html">Как вычислить линейный<br>коэффициент корреляции?</a>
<br>
<a class=classbar href="uravnenie_lineynoy_regressii.html">Уравнение линейной регрессии</a>
<br>
<a class=classbar href="proverka_znachimosti_lineynoy_modeli.html">Проверка значимости линейной<br>корреляционной модели</a>
<br>
<a class=classbar href="model_regressii_indeks_determinacii.html">Модель пАрной регрессии.<br>Индекс детерминации</a>
<br>
<a class=classbar href="nelineynaya_regressiya_primery_resheniy.html">Нелинейная регрессия. Виды и<br>примеры решений</a>
<br>
<a class=classbar href="koefficient_rangovoy_korrelyacii_spirmena.html">Коэффициент ранговой<br>корреляции Спирмена</a>
<br>
<a class=classbar href="koefficient_korrelyacii_fehnera.html">Коэф-т корреляции Фехнера</a>
<br>
<a class=classbar href="uravnenie_mnozhestvennoy_regressii.html">Уравнение множественной<br>линейной регрессии
</a>
</p>
</div>

<noindex>

<p><a href="https://cse.google.ru/cse?cx=partner-pub-4276726786010073:1946131416&amp;ie=Windows-1251&amp;q=&amp;ref=www.mathprofi.ru/#gsc.tab=0" target="_blank"><img src="images/spoisk.png" align="absmiddle" border="0"></a></p>

</noindex>

<p><em><strong>Не нашлось нужной задачи?</strong></em><br>
<a href="skachat_primery_po_vysshei_matematike.html">Сборники готовых решений!</a></p>
<p style="padding-bottom:5px"><em><strong>Не получается пример?</strong></em><br>
<a href="https://mathprofi.com" target="_blank">Задайте вопрос на форуме!<br>>>> mathprofi.com</a></p>


<p class=classbar>Обратная связь:</p>
<p class=classb>

<a href="scripts/faq.html" rel="nofollow">Часто задаваемые вопросы</a><br>
<a href="scripts/gb">Гостевая книга </a>
<a href="scripts/call.html">Отблагодарить автора >>></a>

        <br>
</p>
<p><em>Заметили опечатку / ошибку?<br>Пожалуйста, <a href="scripts/smess/index.php">сообщите</a> мне об этом</em></p>

<noindex>
<div class="adv">

<!-- Yandex.RTB R-A-1373053-2 -->
<div id="yandex_rtb_R-A-1373053-2"></div>
<script>window.yaContextCb.push(()=>{
  Ya.Context.AdvManager.render({
    renderTo: 'yandex_rtb_R-A-1373053-2',
    blockId: 'R-A-1373053-2'
  })
})</script>

</div>

</noindex>

</td>

<td  valign="top"><noindex>
<br>
<table width="690" height="178"  border="0" cellpadding="0" cellspacing="8" align="center">
<tr>

<td align="center" width="508"> 

<div class="advup">

<!-- Yandex.RTB R-A-1373053-6 -->
<div id="yandex_rtb_R-A-1373053-6"></div>
<script>window.yaContextCb.push(()=>{
  Ya.Context.AdvManager.render({
    renderTo: 'yandex_rtb_R-A-1373053-6',
    blockId: 'R-A-1373053-6'
  })
})</script>

</div>

</td>

<td align="center" width="182">

<img src="images/chashka.gif" border="0" title="Успешной подготовки!"><br>

<p></p><a href="lekcii_po_vysshei_matematike.html"><img align="absmiddle" src="images/sun3.png" border="0">&nbsp;&nbsp;Карта сайта</a>

</td>


</tr>
</table>


<hr size="2" width="600" color="gray">


<br></noindex>
  <h1 align="center">22. Модель однофакторной регрессии.<br>Индекс детерминации и индекс корреляции</h1>
  <br>
 
  <p>По доброй традиции сразу разберёмся с терминами. <strong><em>Однофакторная</em></strong><em> регрессия</em> и <strong><em>пАрная</em></strong><em> регрессия</em> – это синонимы. С частным (линейным)  случаем этой модели мы уже имели дело ранее. Так, в <strong><a href="linejnyj_koefficient_korrelyacii.html">Примере 67</a></strong> речь шла о <em>корреляционной  зависимости</em> суммарной успеваемости <em>(признак-результат)</em> от количества прогулов <em>(признак-фактор)</em> за некоторый период времени. В рамках этой модели рассматривается <strong>один</strong> фактор, а посему её называют <em>однофакторной</em>. С другой стороны,  признаков два, а значит, модель можно назвать и <em>пАрной</em>.</p>
  <p>На предыдущих занятиях мы строили уравнения <em>линейной</em> регрессии, причём материал был  рассмотрен в популярном стиле – для самого широкого круга читателей. И,  возможно, вам вполне хватит уроков:</p>
  <p><a href="linejnyj_koefficient_korrelyacii.html">19. Линейный коэффициент корреляции</a><br>
    <a href="uravnenie_lineynoy_regressii.html">20. Уравнение линейной регрессии</a> и <br>
    <a href="proverka_znachimosti_lineynoy_modeli.html">21. Проверка значимости линейной модели</a> – да, даже это  рассмотрели.</p>
  <p>И сейчас 22-й урок, где я разберу <strong>математический смысл</strong> <em>однофакторной  регрессии</em>, при этом <strong>изложенные ниже факты  и методы решения работают как в линейном, так и в нелинейном случае!</strong> Схема  универсальна. После чего мы, конечно, потренируемся в построении <strong><a href="nelineynaya_regressiya_primery_resheniy.html">нелинейных моделей</a></strong>. Вы их долго-долго  ждали и, наконец, дождались!</p>
  <p>Конкретная задача и знакомая выборка, приступаем:</p>
  <p><u>Пример 73</u></p>
  <p>Имеются выборочные данные по <img align="absmiddle" width="36" height="19" src="v/model_regressii_indeks_determinacii_clip_image002.gif"> студентам: <img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image004.gif"> – количество прогулов  за некоторый период времени и <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image006.gif"> – суммарная  успеваемость за этот период:<br>
      <img align="absmiddle" width="381" height="46" src="v/model_regressii_indeks_determinacii_clip_image008.jpg"></p>
  <p>Требуется: </p>
  <p>1) высказать предположение о наличии и направлении <em>корреляционной зависимости</em> <em>признака-результата</em> <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image006_0000.gif"> от <em>признака-фактора </em><img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image004_0000.gif"> и построить <em>диаграмму рассеяния</em>;</p>
  <p>2) анализируя <em>диаграмму  рассеяния</em>, сделать вывод о <em>форме</em> зависимости;</p>
  <p>3) найти уравнение <em>регрессии</em> <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image006_0001.gif"> на <img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image004_0001.gif">;</p>
  <p>4) вычислить <strong><em>индекс детерминации</em></strong> и <strong><em>индекс  корреляции</em></strong>;</p>
  <p>5) проверить значимость выборочного уравнения регрессии <em>на уровне значимости</em> <img align="absmiddle" width="59" height="21" src="v/model_regressii_indeks_determinacii_clip_image010.gif">;</p>
  <p>6) найти <strong><em>среднюю ошибку аппроксимации</em></strong>.<br>
    <br>
    По каждому пункту сделать выводы</p>
  <p>Пункты <strong>1-3</strong> уже  выполнены в <strong><a href="linejnyj_koefficient_korrelyacii.html">Примере 67</a></strong>, и я  конспективно приведу ключевые результаты. В ходе <strong>решения</strong> было высказано предположение о наличии <em>обратной</em> <em>корреляционной  зависимости</em> успеваемости от количества прогулов, что подтвердилось <em>диаграммой рассеяния</em>:<br>
      <img align="absmiddle" width="502" height="315" src="v/model_regressii_indeks_determinacii_clip_image012.jpg"><br>
      <em>Эмпирические точки</em> имеют тенденцию располагаться вдоль прямой, и поэтому корреляционная  зависимость, вероятно, близкА к <em>линейной</em>.  Далее <strong><a href="metod_naimenshih_kvadratov.html">методом наименьших квадратов</a></strong> мы нашли уравнение <em>линейной регрессии</em>,  которое наилучшим образом приближает выборочные данные:<br>
      <img align="absmiddle" width="507" height="319" src="v/model_regressii_indeks_determinacii_clip_image014.jpg"><br>
      <strong>Вопрос: как оценить  качество модели? </strong>Иными словами,<strong> насколько удачно линейная функция приближает эмпирические точки?</strong> На этот  вопрос мы ответили с помощью <a href="linejnyj_koefficient_korrelyacii.html#lkk">линейного коэффициента корреляции</a> и <a href="linejnyj_koefficient_korrelyacii.html#kd">коэффициента детерминации</a>. Однако это  лишь частные показатели. Дело в том, что <strong>существует  общий подход и универсальные показатели, которые годятся как в линейном, так и в  нелинейном случае</strong>:</p>
  <p><strong>4)</strong> Найдём <em>индекс детерминации</em> и <em>индекс корреляции</em>.</p>
  <p>Но прежде вникнем в математическую суть регрессионной  модели. Предположим, что в нашем распоряжении есть данные <strong>только о суммарной успеваемости студентов</strong> за некоторый период  времени: </p>
  <p><img align="absmiddle" width="51" height="23" src="v/model_regressii_indeks_determinacii_clip_image016.gif"> – Иванов;<br>
      <img align="absmiddle" width="59" height="23" src="v/model_regressii_indeks_determinacii_clip_image018.gif"> – Петров;<br>
      <img align="absmiddle" width="59" height="24" src="v/model_regressii_indeks_determinacii_clip_image020.gif"> – Сидоров;<br>
    …<br>
  <img align="absmiddle" width="51" height="24" src="v/model_regressii_indeks_determinacii_clip_image022.gif"> – Попова.</p>
  <p>Вычислим <strong><a href="moda_mediana_generalnaya_i_vyborochnaya_srednyaya.html#s">среднюю</a></strong> успеваемость по выборке:<br>
      <img align="absmiddle" width="475" height="45" src="v/model_regressii_indeks_determinacii_clip_image024.gif"> балла.</p>
  <p>Совершенно понятно, что отдельно взятые значения  успеваемости <img align="absmiddle" width="17" height="24" src="v/model_regressii_indeks_determinacii_clip_image026.gif"> <em>варьируются</em> относительно среднего значения:<br>
      <img align="absmiddle" width="512" height="217" src="v/model_regressii_indeks_determinacii_clip_image028.jpg"><br>
    Я не нарисовал ось <img align="absmiddle" width="28" height="19" src="v/model_regressii_indeks_determinacii_clip_image030.gif">, так как пока мы рассматриваем <strong>единственный</strong> признак – успеваемость. Кстати, все точки можно  было отложить прямо на оси <img align="absmiddle" width="27" height="19" src="v/model_regressii_indeks_determinacii_clip_image032.gif">, но для наглядности пусть будет так.</p>
  <p>Как оценить <em>степень  рассеяния</em> значений <img align="absmiddle" width="17" height="24" src="v/model_regressii_indeks_determinacii_clip_image026_0000.gif"> относительно <img align="absmiddle" width="15" height="20" src="v/model_regressii_indeks_determinacii_clip_image034.gif">? …Если вы затрудняетесь с ответом, то это, конечно,  «двойка»! Меру разброса значений относительно <em>средней</em> характеризует <strong><a href="pokazateli_variacii_generalnaya_i_vyborochnaya_dispersiya.html#d">дисперсия</a></strong>:<br>
      <img align="absmiddle" width="579" height="91" src="v/model_regressii_indeks_determinacii_clip_image036.gif"></p>
  <p>С геометрической точки зрения, сумма <img align="absmiddle" width="79" height="27" src="v/model_regressii_indeks_determinacii_clip_image038.gif"> – это сумма квадратов  хаки-отклонений на рисунке выше. …Все поняли эту фразу? Хаки – это цвет такой.  И это не «каки» :) Кстати, а зачем возводить в квадрат? Это мы тоже разбирали,  когда знакомились с понятием <em>дисперсии</em>:  дело в том, что отклонения <img align="absmiddle" width="41" height="24" src="v/model_regressii_indeks_determinacii_clip_image040.gif"> могут быть как  положительными, так и отрицательными, и просто так их просуммировать не  получится (они взаимоуничтожатся). Чтобы преодолеть эту неприятность и подсчитать  меру вариации – их и возводят в квадраты.</p>
  <p>Промежуточные вычисления удобно оформлять таблицей:<br>
      <img align="absmiddle" width="137" height="214" src="v/model_regressii_indeks_determinacii_clip_image042.jpg"><br>
    Сначала нашли сумму значений <img align="absmiddle" width="37" height="27" src="v/model_regressii_indeks_determinacii_clip_image044.gif"> (левая нижняя ячейка),  затем рассчитали <img align="absmiddle" width="15" height="20" src="v/model_regressii_indeks_determinacii_clip_image034_0000.gif">, заполнили правый столбец и нашли дисперсию <img align="absmiddle" width="21" height="25" src="v/model_regressii_indeks_determinacii_clip_image046.gif">. Технически вычисления проще проводить в Экселе, и если вы  до сих пор не знаете, как это делать, посмотрите, например, <strong><a href="https://www.youtube.com/watch?v=ntjcFWKWU0g&t=3s" target="_blank" rel="nofollow">этот ролик</a></strong>.</p>
  <p>Теперь <strong>содержательный  вопрос</strong>: а почему успеваемость вообще варьируется? На то есть множество  причин, как неслучайных, так и случайных. У всех разные способности, кто-то  учится прилежнее, кто-то прогуливает, кому-то повезло с темой / билетом,  кому-то не повезло и так далее. Причин очень много, и дисперсия  <img align="absmiddle" width="21" height="27" src="v/model_regressii_indeks_determinacii_clip_image048.gif"> учитывает ВСЕ причины.  А посему её называют <strong><em>общей дисперсией</em></strong> и иногда прямо так  и обозначают: <img align="absmiddle" width="35" height="27" src="v/model_regressii_indeks_determinacii_clip_image050.gif">. В качестве эквивалентной меры вариации часто рассматривают  сумму <img align="absmiddle" width="107" height="27" src="v/model_regressii_indeks_determinacii_clip_image052.gif">, которую называют <strong><em>общей суммой квадратов</em></strong>.</p>
  <p>В нашей задаче предложен всего лишь один фактор, который  влияет на успеваемость – количество прогулов:<br>
      <img align="absmiddle" width="512" height="322" src="v/model_regressii_indeks_determinacii_clip_image053.jpg"></p>
  <p>Именно поэтому модель и называют <em>однофакторной</em>, прозанудствую ещё раз. Разумеется, можно рассмотреть  и какой-нибудь другой фактор, влияющий на успеваемость, и даже несколько  факторов, но вот у нас даны только прогулы.</p>
  <p>Далее нами был визуально установлен линейный характер  зависимости, и из решения системы <img align="absmiddle" width="169" height="59" src="v/model_regressii_indeks_determinacii_clip_image055.gif"> мы нашли уравнение  линейной регрессии <img align="absmiddle" width="205" height="21" src="v/model_regressii_indeks_determinacii_clip_image057.gif"> (см. <strong><a href="linejnyj_koefficient_korrelyacii.html">Пример 67</a></strong>, пункт 3).</p>
  <p><strong>В рамках построенной  модели вся вариация успеваемости делится на две части</strong>: </p>
  <p>– <strong><em>факторная</em></strong> <em>(зелёный цвет на рис. ниже)</em> – это та часть, которая объяснИма  уравнением регрессии (фактором прогулов);</p>
  <p>– и <strong><em>остаточная</em></strong> <em>(красный цвет)</em> – часть, которая регрессией не объясняется.</p>
  <p>Так, при количестве прогулов <img align="absmiddle" width="43" height="23" src="v/model_regressii_indeks_determinacii_clip_image059.gif"> отклонение <img align="absmiddle" width="185" height="23" src="v/model_regressii_indeks_determinacii_clip_image061.gif"> <em>(хаки-отрезок слева вверху на рисунке ниже)</em> обусловлено <strong>всеми</strong> причинами, повлиявшими на  успеваемость. При этом точка <img align="absmiddle" width="280" height="23" src="v/model_regressii_indeks_determinacii_clip_image063.gif"> делит данный отрезок  на две части:</p>
  <p>– зелёный участок <img align="absmiddle" width="64" height="23" src="v/model_regressii_indeks_determinacii_clip_image065.gif"> – это часть вариации,  объяснённая уравнением регрессии;</p>
  <p>– красный участок <img align="absmiddle" width="99" height="23" src="v/model_regressii_indeks_determinacii_clip_image067.gif"> – это  <em>остаточная</em> часть вариации, которая уравнением НЕ объяснена. И в самом деле, если значение <img align="absmiddle" width="40" height="23" src="v/model_regressii_indeks_determinacii_clip_image069.gif"> обусловлено  количеством прогулов, то на добавочный <strong><em>остаток</em></strong> <img align="absmiddle" width="16" height="23" src="v/model_regressii_indeks_determinacii_clip_image071.gif"> приходятся другие  факторы.</p>
  <p>Напоминаю, что <strong><a href="metod_naimenshih_kvadratov.html">метод  наименьших квадратов</a></strong> состоит в том, чтобы подобрать ТАКУЮ прямую, чтобы  сумма квадратов <em>остатков</em> <img align="absmiddle" width="37" height="27" src="v/model_regressii_indeks_determinacii_clip_image073.gif"> была наименьшей. Грубо  говоря, оптимальная <em>(синяя)</em> прямая  должна проходить как можно ближе к эмпирическим точкам:<br>
      <img align="absmiddle" width="624" height="345" src="v/model_regressii_indeks_determinacii_clip_image075.jpg"><br>
    Таким образом, речь заходит о <strong><em>факторной сумме квадратов</em></strong>: <img align="absmiddle" width="133" height="27" src="v/model_regressii_indeks_determinacii_clip_image077.gif"> <em>(сумма квадратов зелёных отклонений)</em> и об <strong><em>остаточной сумме квадратов</em></strong> <img align="absmiddle" width="135" height="27" src="v/model_regressii_indeks_determinacii_clip_image079.gif"><em>(сумма квадратов  красных отклонений)<strong>.</strong> </em></p>
  <p>Соответственно, получаем <strong><em>факторную дисперсию</em></strong> <img align="absmiddle" width="153" height="45" src="v/model_regressii_indeks_determinacii_clip_image081.gif"> и <strong><em>остаточную дисперсию</em></strong> <img align="absmiddle" width="151" height="45" src="v/model_regressii_indeks_determinacii_clip_image083.gif">, при этом общая («игрековая») дисперсия успеваемости <img align="absmiddle" width="131" height="27" src="v/model_regressii_indeks_determinacii_clip_image085.gif"> – раскладывается на  дисперсию, объяснённую уравнением регрессии, и дисперсию остаточную. По сути,  это частный случай <strong><a href="dispersii.html">общей, межгрупповой и  внутригрупповой дисперсии</a></strong>. Да, обращаю внимание, что дисперсии у нас <strong><a href="matematicheskaya_statistika.html">выборочные</a></strong> (коль скоро они получены по  выборке студентов) И аналогичное равенство, естественно, справедливо и для  соответствующих сумм квадратов: <img align="absmiddle" width="81" height="24" src="v/model_regressii_indeks_determinacii_clip_image087.gif">.</p>
  <p>Очевидно, что чем длиннее зелёные отрезки, тем короче  красные – тем больше значение <img align="absmiddle" width="40" height="27" src="v/model_regressii_indeks_determinacii_clip_image089.gif"> и меньше <img align="absmiddle" width="33" height="25" src="v/model_regressii_indeks_determinacii_clip_image091.gif">. Тем ближе эмпирические точки расположены к линии регрессии,  и тем выше качество построенной модели. И мерилом такого качества является <strong><em>индекс  детерминации</em></strong>:</p>
  <p><img align="absmiddle" width="77" height="51" src="v/model_regressii_indeks_determinacii_clip_image093.gif"> – это отношение <em>выборочной факторной дисперсии</em> к <em>выборочной общей дисперсии</em>. Следует  заметить, что для расчёта этого индекса дисперсии находить не обязательно,  достаточно ограничиться отношением сумм соответствующих квадратов:</p>
  <p><img align="absmiddle" width="172" height="51" src="v/model_regressii_indeks_determinacii_clip_image095.gif"> – именно такой вариант  встречается в большинстве источников.</p>
  <p>Индекс детерминации изменяется в пределах <img align="absmiddle" width="67" height="24" src="v/model_regressii_indeks_determinacii_clip_image097.gif"> и показывает <em>долю</em> вариации признака-результата,  которая обусловлена признаком-фактором. …Если не очень понятно, то скоро дойдём  до конкретных вычислений и выводов. </p>
  <p>В предельном случае <img align="absmiddle" width="44" height="24" src="v/model_regressii_indeks_determinacii_clip_image099.gif"> все эмпирические точки  расположены на линии регрессии, и речь идёт о строгой функциональной  зависимости, в этом случае <em>признак-фактор</em> модели полностью объясняет всю вариацию признака результата: <img align="absmiddle" width="87" height="27" src="v/model_regressii_indeks_determinacii_clip_image101.gif">. И противоположный случай <img align="absmiddle" width="47" height="24" src="v/model_regressii_indeks_determinacii_clip_image103.gif"> – здесь факторная  дисперсия равна нулю и общая дисперсия полностью объяснИма неучтёнными в модели  причинами:  <img align="absmiddle" width="80" height="27" src="v/model_regressii_indeks_determinacii_clip_image105.gif">. При этом линия регрессии параллельна оси <img align="absmiddle" width="28" height="19" src="v/model_regressii_indeks_determinacii_clip_image030_0000.gif"> и отражает тот факт,  что при изменении значений «икс» среднеожидаемое значение «игрек» остаётся  постоянным. Иными словами, фактор, положенный в основу модели, не оказывает  никакого влияния на результат.</p>
  <p><strong>И ещё раз обращаю  внимание</strong>, что я освещаю <strong>общий подход</strong> – в той или иной задаче <strong>линия регрессия  может быть не только прямой, но и кривой линией</strong>.  </p>
  <p>Ну а теперь вернёмся к нашей задаче и конкретным  вычислениям. Общая сумма квадратов <img align="absmiddle" width="76" height="21" src="v/model_regressii_indeks_determinacii_clip_image108.gif"> и общая дисперсия <img align="absmiddle" width="112" height="27" src="v/model_regressii_indeks_determinacii_clip_image110.gif"> успеваемости уже  рассчитана выше, и <em>индекс детерминации</em> можно найти двумя путями: непосредственно вычислить <em>факторную сумму квадратов</em> <img align="absmiddle" width="23" height="23" src="v/model_regressii_indeks_determinacii_clip_image112.gif"> и отношение <img align="absmiddle" width="60" height="44" src="v/model_regressii_indeks_determinacii_clip_image114.gif">. Либо найти <em>остаточную  сумму квадратов</em> <img align="absmiddle" width="20" height="24" src="v/model_regressii_indeks_determinacii_clip_image116.gif">, после чего из равенства <img align="absmiddle" width="81" height="24" src="v/model_regressii_indeks_determinacii_clip_image087_0000.gif"> выразить <img align="absmiddle" width="81" height="24" src="v/model_regressii_indeks_determinacii_clip_image118.gif"> и получить то же самое  значение: <img align="absmiddle" width="140" height="44" src="v/model_regressii_indeks_determinacii_clip_image120.gif">.</p>
  <p>Второй вариант более популярен, но мы рассмотрим оба, заодно  и проверочка будет.</p>
  <p><strong>Способ первый</strong>:<br>
      <img align="absmiddle" width="411" height="224" src="v/model_regressii_indeks_determinacii_clip_image122.jpg"><br>
    И на всякий случай расчёты для <img align="absmiddle" width="43" height="23" src="v/model_regressii_indeks_determinacii_clip_image059_0000.gif">: сначала находим регрессионное значение <img align="absmiddle" width="278" height="23" src="v/model_regressii_indeks_determinacii_clip_image125.gif">, затем – соответствующий факторный квадрат:<br>
  <img align="absmiddle" width="262" height="24" src="v/model_regressii_indeks_determinacii_clip_image127.gif">. Здесь и далее могут быть некоторые погрешности по причине  округлений; со знаками «равно» и «примерно равно» я тоже не очень строг,  поэтому не судите строго.</p>
  <p>Факторная сумма квадратов найдена в таблице выше <img align="absmiddle" width="88" height="23" src="v/model_regressii_indeks_determinacii_clip_image129.gif">, осталось вычислить <em>индекс  детерминации</em>:</p>
  <p><img align="absmiddle" width="187" height="44" src="v/model_regressii_indeks_determinacii_clip_image131.gif"> – таким образом, в  рамках построенной модели успеваемость на 51,74% зависит от количества  прогулов. Оставшаяся часть вариации успеваемости (48,26%) обусловлена другими  причинами.</p>
  <p>Индекс детерминации совпал с <strong><a href="linejnyj_koefficient_korrelyacii.html#kd">линейным коэффициентом детерминации</a></strong>, который мы нашли в Примере 67,  и я напомню, что <strong>сделанный вывод не  является какой-то «абсолютной истиной»</strong>, это всего лишь оценка в рамках  построенной модели. А модель может быть подобрана как удачно, так и  посредственно, а то и вовсе неудачно.</p>
  <p>Табличка <strong>второго  способа</strong> похожа:<br>
      <img align="absmiddle" width="441" height="220" src="v/model_regressii_indeks_determinacii_clip_image132.jpg"><br>
    – за исключением последнего столбца, в котором  рассчитываются квадраты <em>остатков</em>,  так, для <img align="absmiddle" width="43" height="23" src="v/model_regressii_indeks_determinacii_clip_image059_0001.gif"> получаем: <img align="absmiddle" width="290" height="24" src="v/model_regressii_indeks_determinacii_clip_image134.gif">.</p>
  <p>Таким образом, остаточная сумма квадратов <img align="absmiddle" width="200" height="27" src="v/model_regressii_indeks_determinacii_clip_image136.gif"> и <em>индекс детерминации</em>:</p>
  <p><img align="absmiddle" width="305" height="44" src="v/model_regressii_indeks_determinacii_clip_image138.gif"> – с тем же самым  результатом и выводами.</p>
  <p>Для качественной оценки тесноты связи используют <strong><em>индекс  корреляции</em></strong>:</p>
  <p><img align="absmiddle" width="67" height="29" src="v/model_regressii_indeks_determinacii_clip_image140.gif"> – есть квадратный  корень из <em>индекса детерминации</em>.</p>
  <p>Индекс корреляции тоже изменяется в пределах <img align="absmiddle" width="65" height="23" src="v/model_regressii_indeks_determinacii_clip_image142.gif"> и для оценки качества  модели используют уже знакомую многим <em>шкалу  Чеддока</em>, вот один из её вариантов:<br>
      <img align="absmiddle" width="358" height="191" src="v/model_regressii_indeks_determinacii_clip_image144.jpg"></p>
  <p>В нашей задаче:</p>
  <p><img align="absmiddle" width="183" height="29" src="v/model_regressii_indeks_determinacii_clip_image146.gif"> – таким образом, существует  сильная корреляционная зависимость <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image006_0002.gif"> – суммарной  успеваемости от <img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image004_0002.gif"> – количества прогулов.</p>
  <p>Результат совпал <strong><a href="goryachie_formuly.pdf">по  модулю</a></strong> с <strong><a href="linejnyj_koefficient_korrelyacii.html#lkk">линейным коэффициентом  корреляции</a> </strong><img align="absmiddle" width="66" height="21" src="v/model_regressii_indeks_determinacii_clip_image002_0000.gif">, который мы получили в ходе решения Примера 67. И,  разумеется, вы поняли, что <strong>индекс корреляции  не отражает направление зависимости</strong> (прямая или обратная). Но зато он  годится для оценки качества как линейной, так и нелинейной регрессии! – рАвно,  как и <em>индекс детерминации</em>,  вычисленный по рассмотренной выше методике.</p>
  <p>Индекс детерминации и индекс корреляции – это частный случай <strong><a href="empiricheskie_pokazateli.html#ekd">эмпирического коэффициента детерминации</a></strong> и <strong><a href="empiricheskie_pokazateli.html#eko">эмпирического корреляционного отношения</a> </strong> соответственно.</p>
  <p>5) Оценим <em>значимость</em> построенной регрессионной модели, в данном случае линейной. Эту задачу мы уже  решили <strong><a href="proverka_znachimosti_lineynoy_modeli.html">на предыдущем уроке</a></strong>, но  сейчас я разберу её в общем ключе. </p>
  <p>Кратко напомню постановку вопроса: все вычисления выше и  соответствующие результаты  мы получили  на основе <strong><a href="matematicheskaya_statistika.html">выборочных</a></strong> данных, причём  всего лишь по <img align="absmiddle" width="37" height="19" src="v/model_regressii_indeks_determinacii_clip_image004_0003.gif"> студентам. Но  существует<a href="matematicheskaya_statistika.html"> генеральная совокупность</a> студентов, а значит, и <em>генеральное</em> уравнение регрессии <img align="absmiddle" width="75" height="21" src="v/model_regressii_indeks_determinacii_clip_image006_0003.gif"> с <em>генеральным</em> индексом детерминации <img align="absmiddle" width="23" height="24" src="v/model_regressii_indeks_determinacii_clip_image008.gif">.  И возникает вопрос:  насколько можно доверять полученному выборочному уравнению <img align="absmiddle" width="150" height="21" src="v/model_regressii_indeks_determinacii_clip_image010_0000.gif"> и значению <img align="absmiddle" width="83" height="24" src="v/model_regressii_indeks_determinacii_clip_image012.gif">? – они хорошо характеризуют генеральное уравнение <img align="absmiddle" width="75" height="21" src="v/model_regressii_indeks_determinacii_clip_image006_0004.gif"> и индекс <img align="absmiddle" width="23" height="24" src="v/model_regressii_indeks_determinacii_clip_image008_0000.gif">? Или не надёжно? – например, по причине малой выборки.</p>
  <p><strong>Проверка значимости</strong> <em>выборочного уравнения регрессии</em> <strong>эквивалентна</strong> <strong>проверке значимости </strong><em>выборочного  индекса детерминации</em>. …Кстати, почему? Ну хотя бы по той причине, что <em>факторная сумма квадратов</em> в числителе  формулы <img align="absmiddle" width="60" height="44" src="v/model_regressii_indeks_determinacii_clip_image015.gif"> порождена линией  регрессии (вспоминаем недавний рисунок).</p>
  <p>Итак, <strong><a href="statisticheskie_gipotezy.html">на уровне  значимости</a></strong> <img align="absmiddle" width="59" height="21" src="v/model_regressii_indeks_determinacii_clip_image017.gif"> <em>(согласно условию)</em> проверим <strong><a href="statisticheskie_gipotezy.html">нулевую  гипотезу</a></strong>:</p>
  <p><img align="absmiddle" width="76" height="25" src="v/model_regressii_indeks_determinacii_clip_image019.gif"> – о том, что <u>генеральный</u> индекс детерминации равен нулю, то есть количество прогулов вообще никак (0%) не  влияет на успеваемость.</p>
  <p>– против конкурирующей гипотезы <img align="absmiddle" width="75" height="24" src="v/model_regressii_indeks_determinacii_clip_image021.gif"> – о том, что такое  влияние есть.</p>
  <p>Для проверки гипотезы используем <strong><a href="statisticheskie_gipotezy.html">статистический критерий</a></strong> <img align="absmiddle" width="135" height="49" src="v/model_regressii_indeks_determinacii_clip_image023.gif">, где <img align="absmiddle" width="36" height="25" src="v/model_regressii_indeks_determinacii_clip_image025.gif"> – выборочная <em>факторная сумма квадратов</em>, <img align="absmiddle" width="33" height="25" src="v/model_regressii_indeks_determinacii_clip_image027.gif"> – выборочная <em>остаточная сумма квадратов</em>, а <img align="absmiddle" width="17" height="15" src="v/model_regressii_indeks_determinacii_clip_image029.gif"> – количество факторных  (причинных) переменных</p>
  <p>В нашей модели фактор единственный (успеваемость) <img align="absmiddle" width="39" height="19" src="v/model_regressii_indeks_determinacii_clip_image031.gif">, следовательно, критерий принимает вид <img align="absmiddle" width="119" height="49" src="v/model_regressii_indeks_determinacii_clip_image033.gif">. Эта случайная величина* имеет <em>распределение Фишера (<img align="absmiddle" width="17" height="17" src="v/model_regressii_indeks_determinacii_clip_image035.gif">-распределение)</em> с количеством степеней свободы <img align="absmiddle" width="107" height="23" src="v/model_regressii_indeks_determinacii_clip_image037.gif">.</p>
  <p><strong><em>*</em></strong><em> Эта величина случайна,  поскольку в разных исследованиях мы будем получать разные значения сумм  квадратов, даже при том же объёме выборки.</em></p>
  <p>Для уровня значимости <img align="absmiddle" width="59" height="21" src="v/model_regressii_indeks_determinacii_clip_image017_0000.gif"> и количества степеней  свободы <img align="absmiddle" width="130" height="23" src="v/model_regressii_indeks_determinacii_clip_image040_0000.gif"> <strong><a href="files/u/f_raspredelenie.png" target="_blank">по соответствующей таблице</a></strong> или <strong><a href="files/terver.xls" target="_blank">с  помощью Расчётного макета</a></strong> (пункт 12) определяем <em>критическое значение критерия</em>: <img align="absmiddle" width="291" height="25" src="v/model_regressii_indeks_determinacii_clip_image042.gif"></p>
  <p>Теперь нужно вычислить <em>наблюдаемое  значение критерия</em>. Если окажется что <img align="absmiddle" width="71" height="25" src="v/model_regressii_indeks_determinacii_clip_image044_0000.gif"> <em>(красная область) </em>то гипотезу <img align="absmiddle" width="23" height="24" src="v/model_regressii_indeks_determinacii_clip_image046_0000.gif"> на <em>уровне значимости</em> <img align="absmiddle" width="16" height="15" src="v/model_regressii_indeks_determinacii_clip_image048_0000.gif"> отвергаем. Если <img align="absmiddle" width="71" height="25" src="v/model_regressii_indeks_determinacii_clip_image050_0000.gif">, то отвергать её – оснований нет:<br>
      <img align="absmiddle" width="440" height="80" src="v/model_regressii_indeks_determinacii_clip_image052.jpg"><br>
    В нашей задаче:<br>
  <img align="absmiddle" width="352" height="45" src="v/model_regressii_indeks_determinacii_clip_image054.gif">–  таким образом, на  уровне значимости <img align="absmiddle" width="59" height="21" src="v/model_regressii_indeks_determinacii_clip_image017_0001.gif"> гипотезу <img align="absmiddle" width="76" height="25" src="v/model_regressii_indeks_determinacii_clip_image019_0000.gif"> отвергаем в пользу  конкурирующей гипотезы <img align="absmiddle" width="75" height="24" src="v/model_regressii_indeks_determinacii_clip_image021_0000.gif">.</p>
  <p>На практике <em>факторную  сумму квадратов</em> часто не рассчитывают, обходясь <em>остаточной</em> и <em>общей суммой</em>: <img align="absmiddle" width="160" height="45" src="v/model_regressii_indeks_determinacii_clip_image058.gif"> <em>(из равенства <img align="absmiddle" width="81" height="24" src="v/model_regressii_indeks_determinacii_clip_image060.gif">)</em>, а если найден индекс детерминации, то можно провести  вычисления и через него:<br>
      <img align="absmiddle" width="305" height="48" src="v/model_regressii_indeks_determinacii_clip_image062.gif"> – это наиболее  распространённый вариант.</p>
  <p><strong>Вывод:</strong> выборочный  индекс детерминации  <img align="absmiddle" width="83" height="24" src="v/model_regressii_indeks_determinacii_clip_image064.gif"> статистически значимо  отличается от нуля, следовательно,   статистически значимо и выборочное уравнение <img align="absmiddle" width="150" height="21" src="v/model_regressii_indeks_determinacii_clip_image010_0001.gif">. </p>
  <p><strong>! Но:</strong> из этого  ещё не следует, что построенная модель является качественной. Речь идёт <strong>лишь о её статистической значимости</strong>.  …Не очень понятно? Для понимания можно привести такую фразу: успеваемость  студента <em>статистически значимо</em> отличается  от нуля. Но это может быть как студент-отличник, так и  студент-удовлетворительник, так и почти уже не студент (но с какими-то шансами).</p>
  <p>Вот и в нашей модели так – несмотря на её статистическую  значимость, ещё не факт, что она сильно хорошА. И прояснить ситуацию нам  поможет:</p>
  <p><strong>6)</strong> <em>Средняя ошибка аппроксимации</em>:</p>
  <p><img align="absmiddle" width="177" height="51" src="v/model_regressii_indeks_determinacii_clip_image067_0000.gif">, которая показывает, на сколько процентов <em>в среднем</em> эмпирические значения <img align="absmiddle" width="17" height="24" src="v/model_regressii_indeks_determinacii_clip_image069_0000.gif"> отличаются от  соответствующих значений <img align="absmiddle" width="37" height="24" src="v/model_regressii_indeks_determinacii_clip_image071_0000.gif">, вычисленных по уравнению регрессии.</p>
  <p>Разъясню подробнее. Так, количеству прогулов <img align="absmiddle" width="43" height="23" src="v/model_regressii_indeks_determinacii_clip_image073_0000.gif"> соответствует  эмпирическая успеваемость в <img align="absmiddle" width="59" height="23" src="v/model_regressii_indeks_determinacii_clip_image075.gif"> баллов. А по  полученному уравнению регрессии мы получили <img align="absmiddle" width="278" height="23" src="v/model_regressii_indeks_determinacii_clip_image077_0000.gif"> балла. И возникает  интерес оценить разницу <img align="absmiddle" width="236" height="23" src="v/model_regressii_indeks_determinacii_clip_image079_0000.gif">, для этого её логично соотнести с эмпирическим значением: <img align="absmiddle" width="175" height="45" src="v/model_regressii_indeks_determinacii_clip_image081_0000.gif"> и тут сразу удобно  выразить результат в процентах: <img align="absmiddle" width="267" height="45" src="v/model_regressii_indeks_determinacii_clip_image083_0000.gif">. Таким образом, отклонение <img align="absmiddle" width="148" height="23" src="v/model_regressii_indeks_determinacii_clip_image085_0000.gif"> составляет 13,2% от  эмпирического значения <img align="absmiddle" width="59" height="23" src="v/model_regressii_indeks_determinacii_clip_image075_0000.gif">, что, к слову, прилично (но ещё не до неприличия).</p>
  <p>И формула <img align="absmiddle" width="177" height="51" src="v/model_regressii_indeks_determinacii_clip_image067_0001.gif"> подсчитывает <em>средний</em> процент таких сопоставлений по  всей совокупности. Знак модуля нужен по той причине, что отклонения <img align="absmiddle" width="92" height="24" src="v/model_regressii_indeks_determinacii_clip_image088.gif">, да и сами эмпирические значения <img align="absmiddle" width="17" height="24" src="v/model_regressii_indeks_determinacii_clip_image069_0001.gif"> в общем случае могут  быть отрицательными.</p>
  <p>Совершенно понятно, что чем меньше <em>средняя ошибка аппроксимации</em> <img align="absmiddle" width="17" height="20" src="v/model_regressii_indeks_determinacii_clip_image091_0000.gif">, тем лучше. Хорошим результатом считаются значения ниже  8-10%. В некоторых источниках встречается оценка в 15%, но это, конечно,  многовато; в качестве компромисса будем считать такой результат  удовлетворительным. Впрочем, это всё общие рассуждения – в некоторых задачах  требуется повышенная точность, а в других она не критична.</p>
  <p>Проведём вычисления для нашей задачи, технически предыдущую  таблицу удобно снабдить дополнительным столбцом:<br>
      <img align="absmiddle" width="558" height="249" src="v/model_regressii_indeks_determinacii_clip_image093.jpg"></p>
  <p>В результате <img align="absmiddle" width="163" height="51" src="v/model_regressii_indeks_determinacii_clip_image095_0000.gif"> <em>и средняя ошибка аппроксимации</em>:<br>
      <img align="absmiddle" width="376" height="51" src="v/model_regressii_indeks_determinacii_clip_image097_0000.gif"> – таким образом,  эмпирические <img align="absmiddle" width="17" height="24" src="v/model_regressii_indeks_determinacii_clip_image069_0002.gif"> и соответствующие  регрессионные значения <img align="absmiddle" width="37" height="24" src="v/model_regressii_indeks_determinacii_clip_image071_0001.gif"> различаются <em>в среднем</em> на 16,83%.</p>
  <p><strong>Вывод:</strong> качество  модели удовлетворительно.</p>
  <p>Готово.</p>
  <p>И такие «скользкие» результаты – не случайность, дело в том,  что регрессионная модель чувствительна к так называемым «выбросам» – единичным<strong>*</strong> точкам <em>(<strong>*</strong> то есть, их мало)</em>, которые  далекИ от регрессионной прямой.  <br>
      <img align="absmiddle" width="298" height="197" src="v/model_regressii_indeks_determinacii_clip_image101.jpg"><br>
    Подобные «выбросы» необоснованно увеличивают общую  погрешность и искажают итоговые результаты. И поэтому аномальные значения  стараются исключить из рассмотрения (а студента, очевидно, из института),  достигая более или менее однородного состава совокупности. Кроме того, чтобы  линейная модель была качественной, требуется выполнение <em>условий Гаусса-Маркова</em>, с которыми можно ознакомиться в  многочисленных источниках, в частности тех, которые указаны ниже.</p>
  <p>Я же ограничусь практической стороной вопроса и принципом  «дана задача – нужно решать», невзирая на теоретические условия, предъявляемые  к модели <em>линейной пАрной регрессии</em>. Желающим  ознакомиться с этой моделью более подробно и более строго рекомендую следующую  литературу:</p>
  <p><em>Н. Ш. Кремер Б. А.  Путко Эконометрика</em><br>
      <em>И. И. Елисеева  Эконометрика</em><br>
    и ещё мне понравилась нижегородская методичка ННГАСУ:<br>
  <em>О. В. Любимцев О. Л.  Любимцева Линейные регрессионные модели в эконометрике</em></p>
  <p>Но, должен предупредить, что везде (или почти везде) разные  обозначения, впрочем, это только закалит юного эконометриста :)</p>
  <p>И пояснение по поводу «Эконометрики» – это название  появилось исторически, по той причине, что регрессионные модели часто строили  (и строят) в экономических исследованиях. Да, эконометрика считается  самостоятельной дисциплиной, но с таким же успехом она могла бы называться  какой-нибудь Соционометрикой. Ибо приложений, помимо экономических, просто <s>тьма</s>  свет. Таким образом, то, что мы сейчас изучаем, логичнее считать частью <strong><a href="matematicheskaya_statistika.html">математической статистики</a></strong>.  </p>
   
    <p>И мы продолжаем нарабатывать практику:</p>
  <p><u>Пример 73</u></p>
  <p>В результате выборочного исследования признака <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image103_0000.gif">, зависящего от <img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image105_0000.gif">, получено <img align="absmiddle" width="44" height="19" src="v/model_regressii_indeks_determinacii_clip_image107.gif"> пар значений:<br>
      <img align="absmiddle" width="467" height="45" src="v/model_regressii_indeks_determinacii_clip_image109.jpg"></p>
  <p>Требуется:</p>
  <p>1) методом наименьших квадратов найти <em>уравнение линейной регрессии</em> <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image103_0001.gif"> на <img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image105_0001.gif">;</p>
  <p>2) вычислить <em>индекс  детерминации</em> и <em>индекс корреляции</em>;</p>
  <p>3) проверить значимость полученной модели на уровне  значимости <img align="absmiddle" width="59" height="21" src="v/model_regressii_indeks_determinacii_clip_image111.gif">;</p>
  <p>4) вычислить <em>среднюю  ошибку аппроксимации</em>;</p>
  <p>5) построить диаграмму рассеяния и линию регрессии.</p>
  <p>По каждому пункту сделать выводы.</p>
  <p>Это пример для самостоятельного исследования, все числа <strong><a href="files/u/k_zadache_73.xls">уже в Экселе</a></strong> и вам осталось быстренько  провести вычисления. Не ленимся! В образце, с которым можно свериться внизу  страницы, я придерживался наиболее распространённой схемы решения, а именно,  пункт 1 найден с помощью стандартного алгоритма, который освещён в статье <strong><a href="metod_naimenshih_kvadratov.html">Метод наименьших квадратов</a></strong>. В пункте 2  для нахождения индексов рассчитана <em>остаточная  сумма квадратов</em>, как я уже отмечал, это наиболее ходовой способ.</p>
  <p>И после этого важного примера можно перейти к изучению <strong><a href="nelineynaya_regressiya_primery_resheniy.html">нелинейной регрессии</a></strong>.</p>
  <p>Желаю успехов!</p>
  <p><u>Решения и ответы:</u></p>
  <p><em>Пример 73. <strong>Решение</strong>:</em></p>
  <p><strong><em>1)</em></strong><em> Методом наименьших  квадратов найдём <strong> </strong>уравнение <img align="absmiddle" width="70" height="21" src="v/model_regressii_indeks_determinacii_clip_image113.gif"> линейной регрессии <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image103_0002.gif"> на <img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image105_0002.gif">. Заполним расчётную таблицу:</em><br>
      <em><img align="absmiddle" width="258" height="279" src="v/model_regressii_indeks_determinacii_clip_image117.jpg"></em></p>
  <p><em>Коэффициенты уравнения <img align="absmiddle" width="70" height="21" src="v/model_regressii_indeks_determinacii_clip_image113_0000.gif"> найдём как решение  системы:</em><br>
      <em><img align="absmiddle" width="340" height="59" src="v/model_regressii_indeks_determinacii_clip_image119.gif"></em></p>
  <p><em>Систему решим <strong><a href="pravilo_kramera_matrichnyi_metod.html">по формулам Крамера</a></strong>:</em><br>
      <em><img align="absmiddle" width="364" height="48" src="v/model_regressii_indeks_determinacii_clip_image121.gif">, значит, система имеет единственное решение.</em></p>
  <p><em><img align="absmiddle" width="447" height="209" src="v/model_regressii_indeks_determinacii_clip_image123.gif"></em></p>
  <p><strong><em>! Не забываем</em></strong><em> подставить  полученные значения <img align="absmiddle" width="157" height="21" src="v/model_regressii_indeks_determinacii_clip_image125_0000.gif"> в каждое уравнение  системы, выполнив тем самым проверку.</em></p>
  <p><em>Таким образом, искомое  уравнение регрессии:</em><br>
      <em><img align="absmiddle" width="138" height="21" src="v/model_regressii_indeks_determinacii_clip_image127_0000.gif"> </em></p>
  <p><em>Данное уравнение  показывает, что с увеличением значения «икс» на 1 единицу соответствующее  значение «игрек» увеличивается в среднем на 19,733 единицы. Очевидно, что  корреляционная зависимость прямая («чем больше, тем больше»).</em></p>
  <p><strong><em>2)</em></strong><em> Найдём индекс  детерминации и индекс корреляции. Вычислим среднее значение признака-результата <img align="absmiddle" width="152" height="45" src="v/model_regressii_indeks_determinacii_clip_image129_0000.gif"> и заполним расчётную  таблицу:</em><br>
      <em><img align="absmiddle" width="568" height="288" src="v/model_regressii_indeks_determinacii_clip_image131.jpg"></em><br>
      <em>В результате, общая  сумма квадратов <img align="absmiddle" width="84" height="21" src="v/model_regressii_indeks_determinacii_clip_image133.gif">, остаточная сумма квадратов <img align="absmiddle" width="96" height="24" src="v/model_regressii_indeks_determinacii_clip_image135.gif"> и индекс детерминации:</em><br>
      <em><img align="absmiddle" width="315" height="44" src="v/model_regressii_indeks_determinacii_clip_image137.gif"> – таким образом, в  рамках построенной модели вариация признака <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image103_0003.gif"> на 78,38% обусловлена  изменением признака <img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image105_0003.gif">. Остальные 21,62% вариации обусловлены причинами, не  учтёнными в модели.</em></p>
  <p><em>Вычислим индекс  корреляции:</em><br>
      <em><img align="absmiddle" width="189" height="29" src="v/model_regressii_indeks_determinacii_clip_image141.gif"> – таким образом,  существует сильная корреляционная зависимость признака-результата <img align="absmiddle" width="15" height="17" src="v/model_regressii_indeks_determinacii_clip_image103_0004.gif"> от фактора <img align="absmiddle" width="19" height="17" src="v/model_regressii_indeks_determinacii_clip_image105_0004.gif">.</em></p>
  <p><strong><em>3)</em></strong><em> Оценим значимость  построенной регрессионной модели на уровне значимости <img align="absmiddle" width="59" height="21" src="v/model_regressii_indeks_determinacii_clip_image111_0000.gif">. А именно, проверим нулевую гипотезу <img align="absmiddle" width="76" height="25" src="v/model_regressii_indeks_determinacii_clip_image019_0001.gif"> – о том, что  генеральный индекс детерминации равен нулю, против конкурирующей гипотезы: <img align="absmiddle" width="75" height="24" src="v/model_regressii_indeks_determinacii_clip_image021_0001.gif">.</em></p>
  <p><em>Используем  статистический критерий <img align="absmiddle" width="125" height="51" src="v/model_regressii_indeks_determinacii_clip_image146_0000.gif">, где <img align="absmiddle" width="32" height="27" src="v/model_regressii_indeks_determinacii_clip_image148.gif">  – значение  выборочного индекса детерминации.</em></p>
  <p><em>Для уровня значимости <img align="absmiddle" width="59" height="21" src="v/model_regressii_indeks_determinacii_clip_image111_0001.gif"> и количества степеней  свободы <img align="absmiddle" width="136" height="23" src="v/model_regressii_indeks_determinacii_clip_image151.gif"> <strong><a href="files/u/f_raspredelenie.png" target="_blank">по соответствующей таблице</a></strong> или <strong><a href="files/terver.xls" target="_blank">с  помощью Расчётного макета</a></strong> (пункт 12) определяем критическое значение  критерия: <img align="absmiddle" width="288" height="25" src="v/model_regressii_indeks_determinacii_clip_image153.gif"></em></p>
  <p><em>Вычислим наблюдаемое  значение критерия:</em><br>
      <em><img align="absmiddle" width="230" height="48" src="v/model_regressii_indeks_determinacii_clip_image155.gif"></em></p>
  <p><em>Наблюдаемое значение  критерия попало в критическую область <img align="absmiddle" width="71" height="25" src="v/model_regressii_indeks_determinacii_clip_image044_0001.gif">:</em><br>
      <em><img align="absmiddle" width="440" height="80" src="v/model_regressii_indeks_determinacii_clip_image052_0000.jpg"></em><br>
      <em>–  таким образом, на уровне значимости <img align="absmiddle" width="59" height="21" src="v/model_regressii_indeks_determinacii_clip_image111_0002.gif"> гипотезу <img align="absmiddle" width="76" height="25" src="v/model_regressii_indeks_determinacii_clip_image019_0002.gif"> отвергаем в пользу гипотезы <img align="absmiddle" width="75" height="24" src="v/model_regressii_indeks_determinacii_clip_image021_0002.gif">.</em></p>
  <p><strong><em>Вывод:</em></strong><em> индекс  детерминации  <img align="absmiddle" width="81" height="24" src="v/model_regressii_indeks_determinacii_clip_image159.gif"> статистически значимо  отличен от нуля, следовательно,   статистически значимо и выборочное уравнение <img align="absmiddle" width="150" height="21" src="v/model_regressii_indeks_determinacii_clip_image010_0002.gif">. </em></p>
  <p><strong><em>4)</em></strong><em> Вычислим среднюю  ошибку аппроксимации:</em></p>
  <p><em><img align="absmiddle" width="372" height="51" src="v/model_regressii_indeks_determinacii_clip_image161.gif"> – таким образом,  эмпирические <img align="absmiddle" width="17" height="24" src="v/model_regressii_indeks_determinacii_clip_image069_0003.gif"> и соответствующие  регрессионные значения <img align="absmiddle" width="37" height="24" src="v/model_regressii_indeks_determinacii_clip_image071_0002.gif"> различаются в среднем  почти в два раза, что, конечно, ни в какие ворота.</em></p>
  <p><strong><em>Вывод:</em></strong><em> качество модели  неудовлетворительно.</em></p>
  <p><strong><em>5)</em></strong><em> Построим диаграмму  рассеяния и линию регрессии по двум точкам <img align="absmiddle" width="182" height="21" src="v/model_regressii_indeks_determinacii_clip_image163.gif">:</em><br>
      <em><img align="absmiddle" width="477" height="268" src="v/model_regressii_indeks_determinacii_clip_image165.jpg"></em></p>
  <p><em>И, как мы видим, точки  имеют тенденцию располагаться, скорее, вдоль некоторой кривой. Таким образом,  здесь  целесообразно использовать <strong><a href="nelineynaya_regressiya_primery_resheniy.html">нелинейную регрессию</a></strong>, подобрав удачную  аппроксимирующую кривую.</em></p>
  <p><em> Автор: Емелин Александр </em></p>
  <br>

<p style="padding-bottom:12px"><a href="https://vk.com/mathprofiru" target="_blank" rel="nofollow"><img src="images/vkbuttonnews.png" border="0"></a>&nbsp;<a href="https://mathprofi.com/blog/" target="_blank"><img src="images/bbutton.png" border="0" alt="Блог Емелина Александра"> </p>


<p align="center"> <a href="/">Высшая математика для заочников и не только >>></a></p>
<p align="center"> <i>(Переход на главную страницу) </i> </p> 

<noindex>

<p align="center" style="padding-bottom:7px"><em><a href="scripts/call.html">Как можно отблагодарить автора?</a></em></p>





<p align="center"> <img align="absmiddle" src="images/mark.jpg" border="0"><a class=classbar href="scripts/contented.php"  target="_blank" rel="nofollow"> Contented.ru – онлайн школа дизайна</a>
</p>

<p align="center"> <img align="absmiddle" src="images/mark.jpg" border="0"><a class=classbar href="scripts/skillfactory.php"  target="_blank" rel="nofollow"> SkillFactory – получи востребованную IT профессию!</a>
</p>





<br>


<div class="adv2">

<!-- Yandex.RTB R-A-1373053-4 -->
<div id="yandex_rtb_R-A-1373053-4"></div>
<script>window.yaContextCb.push(()=>{
  Ya.Context.AdvManager.render({
    renderTo: 'yandex_rtb_R-A-1373053-4',
    blockId: 'R-A-1373053-4'
  })
})</script>

</div>


<br><br>
</noindex>
</td>
</tr>
</table>

<table width="980" cellpadding="0" cellspacing="0" align="center">
<tr>
<td  width="980" height="50" > 
  <p class=classf align="center"> © Copyright mathprofi.ru, Александр Емелин, 2010-2023. Копирование материалов сайта запрещено</p>  
<noindex>

<!--LiveInternet counter--><script type="text/javascript"><!--
document.write("<a href='http://www.liveinternet.ru/click' "+
"target=_blank><img src='//counter.yadro.ru/hit?t44.1;r"+
escape(document.referrer)+((typeof(screen)=="undefined")?"":
";s"+screen.width+"*"+screen.height+"*"+(screen.colorDepth?
screen.colorDepth:screen.pixelDepth))+";u"+escape(document.URL)+
";"+Math.random()+
"' alt='' title='LiveInternet' "+
"border='0' width='31' height='31'><\/a>")
//--></script><!--/LiveInternet-->





</noindex>
</tr>
</table>

</body>
</html>